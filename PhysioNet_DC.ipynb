{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b9051860",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### DEMO - Dataset condensation on PhysioNet-2012, 80 condensed samples\n",
    "\n",
    "### import modules\n",
    "import numpy as np\n",
    "from dataset.data_loaders import create_data_loader, build_data_getter\n",
    "import torch,os,copy,logging\n",
    "from configs.config_DM import get_args, get_config\n",
    "from utils.train_utils import get_net, eval_net\n",
    "from utils.misc import init_logging\n",
    "from utils.metric_tracker import MetricTracker, TensorboardWriter\n",
    "from dataset.meta import ds_name_mapping as ds_mp\n",
    "from dataset.meta import net_name_mapping as net_mp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "accc9c93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-12-22,11:45:35-Dataset: PhysioNet-2012, results will be saved to: ../snapshots/PhysioNet_DC\n"
     ]
    }
   ],
   "source": [
    "# get arugments and configs\n",
    "this_args = get_args(strict=False)\n",
    "\n",
    "## setting for PhysioNet-2012\n",
    "this_args.dataset=\"physio\"\n",
    "this_args.dm_ipc=40\n",
    "this_args.save_dir_name=\"PhysioNet_DC\"\n",
    "this_args.pre_process=\"std\"\n",
    "\n",
    "cf=get_config(this_args)\n",
    "\n",
    "# create saving directory\n",
    "os.makedirs(cf.save_dir, exist_ok=True)\n",
    "log_root = logging.getLogger()\n",
    "init_logging(log_root, cf.save_dir)\n",
    "\n",
    "logging.info(f\"Dataset: {ds_mp[cf.ds_name]}, results will be saved to: {cf.save_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5aa16041",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-12-22,11:45:35-Loading train set and creating validation/test data loader for: PhysioNet-2012\n",
      "2022-12-22,11:45:36-Number of samples - train: 5120, validation: 1280, test: 1600\n"
     ]
    }
   ],
   "source": [
    "# the real validation/test data loader\n",
    "logging.info(\"Loading train set and creating validation/test data loader for: {}\".format(ds_mp[cf.ds_name]))\n",
    "\n",
    "### the dataset are not included; please download and pre-process the datasets by yourselves\n",
    "_, val_loader, test_loader, tr_data, tr_lb, prpr = cf.data_loader_fn(\n",
    "    path=cf.data_root, train_batch=cf.train_batch, val_batch=128, test_batch=128, pre_process=cf.pre_process)\n",
    "\n",
    "logging.info(f\"Number of samples - train: {tr_data.shape[0]}, validation: {len(val_loader.dataset)}, test: {len(test_loader.dataset)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "db257a3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-12-22,11:45:36-Initialising condensed dataset from scratch, condensed samples: 80\n",
      "2022-12-22,11:45:37-Original train data shape: (5120, 48, 47), size: 88.125 MBs \n",
      "2022-12-22,11:45:37-Condensed data shape: (80, 48, 47), size: 0.688 MBs \n",
      "2022-12-22,11:45:37-Using Adam optimizer for DC learning ...\n",
      "2022-12-22,11:45:37-Learning condensed dataset on networks: ['TCN-α', 'LSTM-α', 'ViT-α']\n",
      "2022-12-22,11:45:37-Evaluating condensed dataset on networks: ['TCN-α', 'LSTM-α', 'ViT-α', 'ViT-β', 'TRSF-α', 'TRSF-β', 'TCN-β', 'TCN-γ', 'LSTM-β', 'RNN-α', 'RNN-β']\n"
     ]
    }
   ],
   "source": [
    "num_classes = 2 if cf.num_class==1 else cf.num_class  # find class number\n",
    "\n",
    "# build the original train data getter: get random n data from class c\n",
    "get_data = build_data_getter(cf.ds_name, tr_data, tr_lb, cf.device)\n",
    "\n",
    "syn_shape=(num_classes * cf.dm.ipc, cf.dm.syn_time_dim, cf.fea_dim,) # shape of condensed dataset\n",
    "\n",
    "logging.info(f\"Initialising condensed dataset from scratch, condensed samples: {num_classes * cf.dm.ipc}\")\n",
    "data_syn = torch.randn(size=syn_shape, dtype=torch.float, requires_grad=True, device=cf.device)\n",
    "\n",
    "logging.info(\"Original train data shape: {}, size: {:.3f} MBs \".format(tr_data.shape, tr_data.nbytes/(1024**2)))\n",
    "logging.info(\"Condensed data shape: {}, size: {:.3f} MBs \".format(syn_shape, data_syn.detach().cpu().numpy().nbytes/(1024**2)))\n",
    "\n",
    "if cf.ds_name == \"mimic3\" or cf.ds_name==\"physio\" or cf.ds_name == \"covid_b\":\n",
    "    label_syn = np.asarray([np.ones(cf.dm.ipc) * i for i in range(num_classes)])  # [0,0,0, ..., 1,1,1, ]\n",
    "    label_syn = torch.tensor(label_syn, dtype=cf.label_dtype, requires_grad=False, device=cf.device).view(-1)\n",
    "else:\n",
    "    raise NotImplementedError(\"Dataset {} not implemented\".format(cf.ds_name))\n",
    "\n",
    "logging.info(\"Using Adam optimizer for DC learning ...\")\n",
    "optimizer_data = torch.optim.Adam([data_syn, ], lr=cf.dm.lr_data)\n",
    "\n",
    "logging.info(\"Learning condensed dataset on networks: {}\".format([net_mp[e] for e in cf.dm.train_net]))\n",
    "logging.info(\"Evaluating condensed dataset on networks: {}\".format([net_mp[e] for e in cf.dm.eval_net]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4935ff9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-12-22,11:45:37-Creating tensborboard writer ...\n"
     ]
    }
   ],
   "source": [
    "# setup tensorboard writer \n",
    "logging.info(\"Creating tensborboard writer ...\")\n",
    "writer = TensorboardWriter(cf.save_dir, cf.enable_tensorboard)\n",
    "train_metrics = MetricTracker(\"mmd_loss\",writer=writer)\n",
    "eval_keys = tuple(\"syn_auc ({})\".format(n) for n in cf.dm.eval_net)\n",
    "eval_metric = MetricTracker(*eval_keys, writer=writer)\n",
    "all_test_auc = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7fa1e033",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-12-22,11:45:37-DC learning starts ...\n",
      "2022-12-22,11:45:38-iter = 0000, MMD loss = 0.0000165\n",
      "2022-12-22,11:46:28-iter = 1000, MMD loss = 0.0000003\n",
      "2022-12-22,11:47:16-iter = 2000, MMD loss = 0.0000528\n",
      "2022-12-22,11:48:03-iter = 3000, MMD loss = 0.0000462\n",
      "2022-12-22,11:48:52-iter = 4000, MMD loss = 0.0001433\n",
      "2022-12-22,11:49:41-iter = 5000, MMD loss = 0.0002874\n",
      "2022-12-22,11:50:29-iter = 6000, MMD loss = 0.0003952\n",
      "2022-12-22,11:51:18-iter = 7000, MMD loss = 0.0000014\n",
      "2022-12-22,11:52:06-iter = 8000, MMD loss = 0.0000193\n",
      "2022-12-22,11:52:54-iter = 9000, MMD loss = 0.0000048\n",
      "2022-12-22,11:53:43-iter = 10000, MMD loss = 0.0000014\n",
      "2022-12-22,11:54:31-iter = 11000, MMD loss = 0.0000022\n",
      "2022-12-22,11:55:19-iter = 12000, MMD loss = 0.0000025\n",
      "2022-12-22,11:56:08-iter = 13000, MMD loss = 0.0000007\n",
      "2022-12-22,11:56:58-iter = 14000, MMD loss = 0.0006449\n",
      "2022-12-22,11:57:48-iter = 15000, MMD loss = 0.0001399\n",
      "2022-12-22,11:58:36-iter = 16000, MMD loss = 0.0000690\n",
      "2022-12-22,11:59:25-iter = 17000, MMD loss = 0.0000008\n",
      "2022-12-22,12:00:15-iter = 18000, MMD loss = 0.0000009\n",
      "2022-12-22,12:01:04-iter = 19000, MMD loss = 0.0000016\n",
      "2022-12-22,12:01:54-iter = 20000, MMD loss = 0.0000266\n",
      "2022-12-22,12:02:44-iter = 21000, MMD loss = 0.0000011\n",
      "2022-12-22,12:03:33-iter = 22000, MMD loss = 0.0000244\n",
      "2022-12-22,12:04:23-iter = 23000, MMD loss = 0.0000038\n",
      "2022-12-22,12:05:12-iter = 24000, MMD loss = 0.0000001\n",
      "2022-12-22,12:05:12-Learning completed.\n"
     ]
    }
   ],
   "source": [
    "logging.info('DC learning starts ...')\n",
    "optimizer_data.zero_grad()\n",
    "\n",
    "#### Learn condensed data ######\n",
    "for it in range(cf.dm.iteration + 1):\n",
    "\n",
    "    tr_net = np.random.choice(cf.dm.train_net)   # randomly pick a network from train network candidates\n",
    "    net = get_net(tr_net, **cf[tr_net+\"_args\"]).to(cf.device)   # get a random model\n",
    "    net.train()\n",
    "    for param in list(net.parameters()):\n",
    "        param.requires_grad = False\n",
    "    loss_avg = 0\n",
    "\n",
    "    # compute MMD loss\n",
    "    loss = torch.tensor(0.0).to(cf.device)\n",
    "    for _, c in enumerate(range(num_classes)):\n",
    "        # the batch size should not exceed total samples of this class\n",
    "        this_batch_real = min(len(get_data.indices_class[c]), cf.dm.batch_real)\n",
    "        batch_data_real = get_data(c, this_batch_real)\n",
    "        batch_data_syn = data_syn[c * cf.dm.ipc : (c + 1) * cf.dm.ipc]\n",
    "\n",
    "        output_real = net(batch_data_real).detach()\n",
    "        output_syn = net(batch_data_syn)\n",
    "\n",
    "        loss += torch.sum((torch.mean(output_real, dim=0) - torch.mean(output_syn, dim=0)) ** 2)\n",
    "\n",
    "    # update condensed data\n",
    "    optimizer_data.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer_data.step()\n",
    "    loss_avg += loss.item()\n",
    "    loss_avg /= (num_classes)\n",
    "    if train_metrics.writer is not None:\n",
    "        train_metrics.writer.set_step(it)\n",
    "    train_metrics.update(\"mmd_loss\", loss_avg)\n",
    "\n",
    "    if it % cf.dm.logging_iter == 0:\n",
    "        logging.info('iter = {:04d}, MMD loss = {:.7f}'.format(it, loss_avg))\n",
    "        \n",
    "logging.info('Learning completed.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d01b952e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-12-22,12:05:12-Evaluating condensed data on network: TCN-α ...\n",
      "2022-12-22,12:05:15-Eval 01/05, test auc: 0.8136\n",
      "2022-12-22,12:05:19-Eval 02/05, test auc: 0.8013\n",
      "2022-12-22,12:05:22-Eval 03/05, test auc: 0.8087\n",
      "2022-12-22,12:05:26-Eval 04/05, test auc: 0.8032\n",
      "2022-12-22,12:05:29-Eval 05/05, test auc: 0.8135\n",
      "2022-12-22,12:05:29-Condensed data test AUC (TCN-α): 0.8081±0.0051\n",
      "\n",
      "2022-12-22,12:05:29-Evaluating condensed data on network: LSTM-α ...\n",
      "2022-12-22,12:05:32-Eval 01/05, test auc: 0.8112\n",
      "2022-12-22,12:05:35-Eval 02/05, test auc: 0.8081\n",
      "2022-12-22,12:05:38-Eval 03/05, test auc: 0.8241\n",
      "2022-12-22,12:05:41-Eval 04/05, test auc: 0.8180\n",
      "2022-12-22,12:05:44-Eval 05/05, test auc: 0.8224\n",
      "2022-12-22,12:05:44-Condensed data test AUC (LSTM-α): 0.8167±0.0062\n",
      "\n",
      "2022-12-22,12:05:44-Evaluating condensed data on network: ViT-α ...\n",
      "2022-12-22,12:05:50-Eval 01/05, test auc: 0.8037\n",
      "2022-12-22,12:05:55-Eval 02/05, test auc: 0.7957\n",
      "2022-12-22,12:06:01-Eval 03/05, test auc: 0.7985\n",
      "2022-12-22,12:06:07-Eval 04/05, test auc: 0.7832\n",
      "2022-12-22,12:06:13-Eval 05/05, test auc: 0.8020\n",
      "2022-12-22,12:06:13-Condensed data test AUC (ViT-α): 0.7966±0.0073\n",
      "\n",
      "2022-12-22,12:06:13-Evaluating condensed data on network: ViT-β ...\n",
      "2022-12-22,12:06:18-Eval 01/05, test auc: 0.8060\n",
      "2022-12-22,12:06:23-Eval 02/05, test auc: 0.7741\n",
      "2022-12-22,12:06:28-Eval 03/05, test auc: 0.7788\n",
      "2022-12-22,12:06:33-Eval 04/05, test auc: 0.7925\n",
      "2022-12-22,12:06:38-Eval 05/05, test auc: 0.8082\n",
      "2022-12-22,12:06:38-Condensed data test AUC (ViT-β): 0.7919±0.0138\n",
      "\n",
      "2022-12-22,12:06:38-Evaluating condensed data on network: TRSF-α ...\n",
      "2022-12-22,12:06:42-Eval 01/05, test auc: 0.7967\n",
      "2022-12-22,12:06:45-Eval 02/05, test auc: 0.7902\n",
      "2022-12-22,12:06:48-Eval 03/05, test auc: 0.7976\n",
      "2022-12-22,12:06:51-Eval 04/05, test auc: 0.7790\n",
      "2022-12-22,12:06:55-Eval 05/05, test auc: 0.7939\n",
      "2022-12-22,12:06:55-Condensed data test AUC (TRSF-α): 0.7915±0.0068\n",
      "\n",
      "2022-12-22,12:06:55-Evaluating condensed data on network: TRSF-β ...\n",
      "2022-12-22,12:06:58-Eval 01/05, test auc: 0.7771\n",
      "2022-12-22,12:07:01-Eval 02/05, test auc: 0.7838\n",
      "2022-12-22,12:07:04-Eval 03/05, test auc: 0.7967\n",
      "2022-12-22,12:07:07-Eval 04/05, test auc: 0.7795\n",
      "2022-12-22,12:07:10-Eval 05/05, test auc: 0.7734\n",
      "2022-12-22,12:07:10-Condensed data test AUC (TRSF-β): 0.7821±0.0080\n",
      "\n",
      "2022-12-22,12:07:10-Evaluating condensed data on network: TCN-β ...\n",
      "2022-12-22,12:07:11-Eval 01/05, test auc: 0.7966\n",
      "2022-12-22,12:07:13-Eval 02/05, test auc: 0.8063\n",
      "2022-12-22,12:07:15-Eval 03/05, test auc: 0.8121\n",
      "2022-12-22,12:07:16-Eval 04/05, test auc: 0.7974\n",
      "2022-12-22,12:07:18-Eval 05/05, test auc: 0.8139\n",
      "2022-12-22,12:07:18-Condensed data test AUC (TCN-β): 0.8053±0.0072\n",
      "\n",
      "2022-12-22,12:07:18-Evaluating condensed data on network: TCN-γ ...\n",
      "2022-12-22,12:07:21-Eval 01/05, test auc: 0.8143\n",
      "2022-12-22,12:07:23-Eval 02/05, test auc: 0.7977\n",
      "2022-12-22,12:07:26-Eval 03/05, test auc: 0.7954\n",
      "2022-12-22,12:07:28-Eval 04/05, test auc: 0.8075\n",
      "2022-12-22,12:07:31-Eval 05/05, test auc: 0.8065\n",
      "2022-12-22,12:07:31-Condensed data test AUC (TCN-γ): 0.8043±0.0069\n",
      "\n",
      "2022-12-22,12:07:31-Evaluating condensed data on network: LSTM-β ...\n",
      "2022-12-22,12:07:34-Eval 01/05, test auc: 0.8079\n",
      "2022-12-22,12:07:37-Eval 02/05, test auc: 0.8108\n",
      "2022-12-22,12:07:41-Eval 03/05, test auc: 0.8108\n",
      "2022-12-22,12:07:44-Eval 04/05, test auc: 0.8131\n",
      "2022-12-22,12:07:47-Eval 05/05, test auc: 0.8234\n",
      "2022-12-22,12:07:47-Condensed data test AUC (LSTM-β): 0.8132±0.0054\n",
      "\n",
      "2022-12-22,12:07:47-Evaluating condensed data on network: RNN-α ...\n",
      "2022-12-22,12:07:50-Eval 01/05, test auc: 0.8222\n",
      "2022-12-22,12:07:53-Eval 02/05, test auc: 0.8301\n",
      "2022-12-22,12:07:56-Eval 03/05, test auc: 0.8165\n",
      "2022-12-22,12:07:59-Eval 04/05, test auc: 0.8291\n",
      "2022-12-22,12:08:02-Eval 05/05, test auc: 0.8139\n",
      "2022-12-22,12:08:02-Condensed data test AUC (RNN-α): 0.8224±0.0065\n",
      "\n",
      "2022-12-22,12:08:02-Evaluating condensed data on network: RNN-β ...\n",
      "2022-12-22,12:08:05-Eval 01/05, test auc: 0.8150\n",
      "2022-12-22,12:08:09-Eval 02/05, test auc: 0.8062\n",
      "2022-12-22,12:08:12-Eval 03/05, test auc: 0.8011\n",
      "2022-12-22,12:08:15-Eval 04/05, test auc: 0.8101\n",
      "2022-12-22,12:08:19-Eval 05/05, test auc: 0.8157\n",
      "2022-12-22,12:08:19-Condensed data test AUC (RNN-β): 0.8096±0.0055\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#### Evaluate condensed data ####\n",
    "aucs = dict()\n",
    "for this_net in cf.dm.eval_net:  # iterates through all networks to evaluate condensed dataset\n",
    "    \n",
    "    logging.info(\"Evaluating condensed data on network: {} ...\".format(net_mp[this_net]))\n",
    "    aucs[this_net] = []\n",
    "\n",
    "    for it_eval in range(cf.dm.num_eval):\n",
    "        net_eval = get_net(this_net, **cf[this_net+\"_args\"]).to(cf.device)  # get a random model\n",
    "        # avoid any unaware modification\n",
    "        data_syn_eval, label_syn_eval = \\\n",
    "            copy.deepcopy(data_syn.detach()), copy.deepcopy(label_syn.detach())\n",
    "\n",
    "        # create a data loader from condensed dataset\n",
    "        syn_train_loader = create_data_loader(\n",
    "            data_syn_eval, label_syn_eval, batch_size=cf.train_batch, sampler=False)\n",
    "\n",
    "        # evaluate a network on this condensed dataset\n",
    "        _, test_auc = eval_net(\n",
    "            net_eval, syn_train_loader, val_loader, test_loader,\n",
    "            lr=cf.lr, epochs=cf.epochs, weight_decay=cf.weight_decay,\n",
    "            save_dir=cf.save_dir, val_metric=cf.val_metric, device=cf.device,\n",
    "            early_stop=cf.early_stop, early_stop_metric=cf.early_stop_metric,\n",
    "        )\n",
    "\n",
    "        logging.info(\"Eval {:02d}/{:02d}, test auc: {:.4f}\".format(it_eval+1, cf.dm.num_eval, test_auc), )\n",
    "        aucs[this_net].append(test_auc)\n",
    "\n",
    "    logging.info(\"Condensed data test AUC ({}): {:.4f}±{:.4f}\\n\".format(\n",
    "        net_mp[this_net], np.mean(aucs[this_net]), np.std(aucs[this_net])))\n",
    "    \n",
    "    if eval_metric.writer is not None:\n",
    "        eval_metric.writer.set_step(it, mode=\"eval\")\n",
    "    eval_metric.update(\"syn_auc ({})\".format(this_net), np.mean(aucs[this_net]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0f5d480f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-12-22,12:08:19-Condensed data (80) test AUC (all 11 networks): 0.8038±0.0138\n"
     ]
    }
   ],
   "source": [
    "all_test_auc[\"iter_\" + str(it)] = aucs\n",
    "\n",
    "final_test_auc, auc_all = dict(), []\n",
    "    \n",
    "for this_net in cf.dm.eval_net:\n",
    "    final_test_auc[this_net]=aucs[this_net]\n",
    "    auc_all+=aucs[this_net]\n",
    "\n",
    "## overall test performance\n",
    "logging.info(\"Condensed data ({}) test AUC (all {} networks): {:.4f}±{:.4f}\".format(data_syn.shape[0],len(cf.dm.eval_net), np.mean(auc_all), np.std(auc_all)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "67ad1bde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-12-22,12:08:19-Condensed dataset saved to : ../snapshots/PhysioNet_DC/syn_data.pt\n"
     ]
    }
   ],
   "source": [
    "# save condensed dataset\n",
    "syn_data_save_path = os.path.join(cf.save_dir, \"syn_data.pt\")\n",
    "data_save=[]\n",
    "data_save.append([copy.deepcopy(data_syn.detach().cpu()), copy.deepcopy(label_syn.detach().cpu())])\n",
    "torch.save(\n",
    "    {'syn_dataset': data_save,\n",
    "     'final_test_auc': final_test_auc,\n",
    "     \"all_test_auc\":all_test_auc},\n",
    "    syn_data_save_path)\n",
    "logging.info(\"Condensed dataset saved to : {}\".format(syn_data_save_path))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
