{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e62f84e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### DEMO - Dataset condensation on Coswara (breathes), 80 condensed samples\n",
    "\n",
    "### import modules\n",
    "import numpy as np\n",
    "from dataset.data_loaders import create_data_loader, build_data_getter\n",
    "import torch,os,copy,logging\n",
    "from configs.config_DM import get_args, get_config\n",
    "from utils.train_utils import get_net, eval_net\n",
    "from utils.misc import init_logging\n",
    "from utils.metric_tracker import MetricTracker, TensorboardWriter\n",
    "from dataset.meta import ds_name_mapping as ds_mp\n",
    "from dataset.meta import net_name_mapping as net_mp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a65b06fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-12-22,18:37:36-Dataset: Coswara, results will be saved to: ../snapshots/Coswara_DC\n"
     ]
    }
   ],
   "source": [
    "# get arugments and configs\n",
    "this_args = get_args(strict=False)\n",
    "\n",
    "## setting for Coswara (breathes)\n",
    "this_args.dataset=\"covid_b\"\n",
    "this_args.dm_ipc=40\n",
    "this_args.save_dir_name=\"Coswara_DC\"\n",
    "this_args.pre_process=\"std\"\n",
    "\n",
    "cf=get_config(this_args)\n",
    "\n",
    "# create saving directory\n",
    "os.makedirs(cf.save_dir, exist_ok=True)\n",
    "log_root = logging.getLogger()\n",
    "init_logging(log_root, cf.save_dir)\n",
    "\n",
    "logging.info(f\"Dataset: {ds_mp[cf.ds_name]}, results will be saved to: {cf.save_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cf1288b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-12-22,18:37:37-Loading train set and creating validation/test data loader for: Coswara\n",
      "2022-12-22,18:37:37-Number of samples - train: 987, validation: 175, test: 206\n"
     ]
    }
   ],
   "source": [
    "# the real validation/test data loader\n",
    "logging.info(\"Loading train set and creating validation/test data loader for: {}\".format(ds_mp[cf.ds_name]))\n",
    "\n",
    "### the dataset are not included; please download and pre-process the datasets by yourselves\n",
    "_, val_loader, test_loader, tr_data, tr_lb, prpr = cf.data_loader_fn(\n",
    "    path=cf.data_root, train_batch=cf.train_batch, val_batch=128, test_batch=128, pre_process=cf.pre_process)\n",
    "\n",
    "logging.info(f\"Number of samples - train: {tr_data.shape[0]}, validation: {len(val_loader.dataset)}, test: {len(test_loader.dataset)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "61d833a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-12-22,18:37:37-Initialising condensed dataset from scratch, condensed samples: 80\n",
      "2022-12-22,18:37:38-Original train data shape: (987, 96, 64), size: 46.266 MBs \n",
      "2022-12-22,18:37:38-Condensed data shape: (80, 96, 64), size: 1.875 MBs \n",
      "2022-12-22,18:37:38-Using Adam optimizer for DC learning ...\n",
      "2022-12-22,18:37:38-Learning condensed dataset on networks: ['TCN-α', 'LSTM-α', 'ViT-α']\n",
      "2022-12-22,18:37:38-Evaluating condensed dataset on networks: ['TCN-α', 'LSTM-α', 'ViT-α', 'ViT-β', 'TRSF-α', 'TRSF-β', 'TCN-β', 'TCN-γ', 'LSTM-β', 'RNN-α', 'RNN-β']\n"
     ]
    }
   ],
   "source": [
    "num_classes = 2 if cf.num_class==1 else cf.num_class  # find class number\n",
    "\n",
    "# build the original train data getter: get random n data from class c\n",
    "get_data = build_data_getter(cf.ds_name, tr_data, tr_lb, cf.device)\n",
    "\n",
    "syn_shape=(num_classes * cf.dm.ipc, cf.dm.syn_time_dim, cf.fea_dim,) # shape of condensed dataset\n",
    "\n",
    "logging.info(f\"Initialising condensed dataset from scratch, condensed samples: {num_classes * cf.dm.ipc}\")\n",
    "data_syn = torch.randn(size=syn_shape, dtype=torch.float, requires_grad=True, device=cf.device)\n",
    "\n",
    "logging.info(\"Original train data shape: {}, size: {:.3f} MBs \".format(tr_data.shape, tr_data.nbytes/(1024**2)))\n",
    "logging.info(\"Condensed data shape: {}, size: {:.3f} MBs \".format(syn_shape, data_syn.detach().cpu().numpy().nbytes/(1024**2)))\n",
    "\n",
    "if cf.ds_name == \"mimic3\" or cf.ds_name==\"physio\" or cf.ds_name == \"covid_b\":\n",
    "    label_syn = np.asarray([np.ones(cf.dm.ipc) * i for i in range(num_classes)])  # [0,0,0, ..., 1,1,1, ]\n",
    "    label_syn = torch.tensor(label_syn, dtype=cf.label_dtype, requires_grad=False, device=cf.device).view(-1)\n",
    "else:\n",
    "    raise NotImplementedError(\"Dataset {} not implemented\".format(cf.ds_name))\n",
    "\n",
    "logging.info(\"Using Adam optimizer for DC learning ...\")\n",
    "optimizer_data = torch.optim.Adam([data_syn, ], lr=cf.dm.lr_data)\n",
    "\n",
    "logging.info(\"Learning condensed dataset on networks: {}\".format([net_mp[e] for e in cf.dm.train_net]))\n",
    "logging.info(\"Evaluating condensed dataset on networks: {}\".format([net_mp[e] for e in cf.dm.eval_net]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9289d7fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-12-22,18:37:38-Creating tensborboard writer ...\n"
     ]
    }
   ],
   "source": [
    "# setup tensorboard writer \n",
    "logging.info(\"Creating tensborboard writer ...\")\n",
    "writer = TensorboardWriter(cf.save_dir, cf.enable_tensorboard)\n",
    "train_metrics = MetricTracker(\"mmd_loss\",writer=writer)\n",
    "eval_keys = tuple(\"syn_auc ({})\".format(n) for n in cf.dm.eval_net)\n",
    "eval_metric = MetricTracker(*eval_keys, writer=writer)\n",
    "all_test_auc = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a448a351",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-12-22,18:37:38-DC learning starts ...\n",
      "2022-12-22,18:37:40-iter = 0000, MMD loss = 0.0000440\n",
      "2022-12-22,18:39:01-iter = 1000, MMD loss = 0.0000196\n",
      "2022-12-22,18:40:21-iter = 2000, MMD loss = 0.0000227\n",
      "2022-12-22,18:41:41-iter = 3000, MMD loss = 0.0001913\n",
      "2022-12-22,18:43:00-iter = 4000, MMD loss = 0.0000269\n",
      "2022-12-22,18:44:21-iter = 5000, MMD loss = 0.0000196\n",
      "2022-12-22,18:45:41-iter = 6000, MMD loss = 0.0000085\n",
      "2022-12-22,18:46:59-iter = 7000, MMD loss = 0.0000266\n",
      "2022-12-22,18:48:20-iter = 8000, MMD loss = 0.0002047\n",
      "2022-12-22,18:49:38-iter = 9000, MMD loss = 0.0000030\n",
      "2022-12-22,18:50:57-iter = 10000, MMD loss = 0.0000370\n",
      "2022-12-22,18:52:17-iter = 11000, MMD loss = 0.0000068\n",
      "2022-12-22,18:53:37-iter = 12000, MMD loss = 0.0000040\n",
      "2022-12-22,18:54:59-iter = 13000, MMD loss = 0.0001837\n",
      "2022-12-22,18:56:24-iter = 14000, MMD loss = 0.0000771\n",
      "2022-12-22,18:57:44-iter = 15000, MMD loss = 0.0000291\n",
      "2022-12-22,18:59:05-iter = 16000, MMD loss = 0.0001000\n",
      "2022-12-22,19:00:25-iter = 17000, MMD loss = 0.0000234\n",
      "2022-12-22,19:01:45-iter = 18000, MMD loss = 0.0000473\n",
      "2022-12-22,19:03:08-iter = 19000, MMD loss = 0.0001537\n",
      "2022-12-22,19:04:28-iter = 20000, MMD loss = 0.0000341\n",
      "2022-12-22,19:05:48-iter = 21000, MMD loss = 0.0000271\n",
      "2022-12-22,19:07:08-iter = 22000, MMD loss = 0.0000297\n",
      "2022-12-22,19:08:31-iter = 23000, MMD loss = 0.0003137\n",
      "2022-12-22,19:09:52-iter = 24000, MMD loss = 0.0000046\n",
      "2022-12-22,19:09:52-Learning completed.\n"
     ]
    }
   ],
   "source": [
    "logging.info('DC learning starts ...')\n",
    "optimizer_data.zero_grad()\n",
    "\n",
    "#### Learn condensed data ######\n",
    "for it in range(cf.dm.iteration + 1):\n",
    "\n",
    "    tr_net = np.random.choice(cf.dm.train_net)   # randomly pick a network from train network candidates\n",
    "    net = get_net(tr_net, **cf[tr_net+\"_args\"]).to(cf.device)   # get a random model\n",
    "    net.train()\n",
    "    for param in list(net.parameters()):\n",
    "        param.requires_grad = False\n",
    "    loss_avg = 0\n",
    "\n",
    "    # compute MMD loss\n",
    "    loss = torch.tensor(0.0).to(cf.device)\n",
    "    for _, c in enumerate(range(num_classes)):\n",
    "        # the batch size should not exceed total samples of this class\n",
    "        this_batch_real = min(len(get_data.indices_class[c]), cf.dm.batch_real)\n",
    "        batch_data_real = get_data(c, this_batch_real)\n",
    "        batch_data_syn = data_syn[c * cf.dm.ipc : (c + 1) * cf.dm.ipc]\n",
    "\n",
    "        output_real = net(batch_data_real).detach()\n",
    "        output_syn = net(batch_data_syn)\n",
    "\n",
    "        loss += torch.sum((torch.mean(output_real, dim=0) - torch.mean(output_syn, dim=0)) ** 2)\n",
    "\n",
    "    # update condensed data\n",
    "    optimizer_data.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer_data.step()\n",
    "    loss_avg += loss.item()\n",
    "    loss_avg /= (num_classes)\n",
    "    if train_metrics.writer is not None:\n",
    "        train_metrics.writer.set_step(it)\n",
    "    train_metrics.update(\"mmd_loss\", loss_avg)\n",
    "\n",
    "    if it % cf.dm.logging_iter == 0:\n",
    "        logging.info('iter = {:04d}, MMD loss = {:.7f}'.format(it, loss_avg))\n",
    "        \n",
    "logging.info('Learning completed.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "52598d9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-12-22,19:09:52-Evaluating condensed data on network: TCN-α ...\n",
      "2022-12-22,19:09:54-Eval 01/05, test auc: 0.6422\n",
      "2022-12-22,19:09:57-Eval 02/05, test auc: 0.6425\n",
      "2022-12-22,19:09:59-Eval 03/05, test auc: 0.6405\n",
      "2022-12-22,19:10:01-Eval 04/05, test auc: 0.6526\n",
      "2022-12-22,19:10:03-Eval 05/05, test auc: 0.6517\n",
      "2022-12-22,19:10:03-Condensed data test AUC (TCN-α): 0.6459±0.0051\n",
      "\n",
      "2022-12-22,19:10:03-Evaluating condensed data on network: LSTM-α ...\n",
      "2022-12-22,19:10:06-Eval 01/05, test auc: 0.6715\n",
      "2022-12-22,19:10:09-Eval 02/05, test auc: 0.6795\n",
      "2022-12-22,19:10:12-Eval 03/05, test auc: 0.6475\n",
      "2022-12-22,19:10:15-Eval 04/05, test auc: 0.6482\n",
      "2022-12-22,19:10:17-Eval 05/05, test auc: 0.6424\n",
      "2022-12-22,19:10:17-Condensed data test AUC (LSTM-α): 0.6578±0.0148\n",
      "\n",
      "2022-12-22,19:10:17-Evaluating condensed data on network: ViT-α ...\n",
      "2022-12-22,19:10:20-Eval 01/05, test auc: 0.6566\n",
      "2022-12-22,19:10:24-Eval 02/05, test auc: 0.6399\n",
      "2022-12-22,19:10:28-Eval 03/05, test auc: 0.6708\n",
      "2022-12-22,19:10:32-Eval 04/05, test auc: 0.6779\n",
      "2022-12-22,19:10:36-Eval 05/05, test auc: 0.6257\n",
      "2022-12-22,19:10:36-Condensed data test AUC (ViT-α): 0.6542±0.0193\n",
      "\n",
      "2022-12-22,19:10:36-Evaluating condensed data on network: ViT-β ...\n",
      "2022-12-22,19:10:39-Eval 01/05, test auc: 0.6386\n",
      "2022-12-22,19:10:42-Eval 02/05, test auc: 0.6461\n",
      "2022-12-22,19:10:45-Eval 03/05, test auc: 0.6102\n",
      "2022-12-22,19:10:48-Eval 04/05, test auc: 0.6750\n",
      "2022-12-22,19:10:50-Eval 05/05, test auc: 0.6475\n",
      "2022-12-22,19:10:50-Condensed data test AUC (ViT-β): 0.6435±0.0207\n",
      "\n",
      "2022-12-22,19:10:50-Evaluating condensed data on network: TRSF-α ...\n",
      "2022-12-22,19:10:52-Eval 01/05, test auc: 0.6561\n",
      "2022-12-22,19:10:54-Eval 02/05, test auc: 0.6496\n",
      "2022-12-22,19:10:56-Eval 03/05, test auc: 0.6611\n",
      "2022-12-22,19:10:58-Eval 04/05, test auc: 0.6425\n",
      "2022-12-22,19:10:59-Eval 05/05, test auc: 0.6373\n",
      "2022-12-22,19:10:59-Condensed data test AUC (TRSF-α): 0.6493±0.0087\n",
      "\n",
      "2022-12-22,19:10:59-Evaluating condensed data on network: TRSF-β ...\n",
      "2022-12-22,19:11:01-Eval 01/05, test auc: 0.6930\n",
      "2022-12-22,19:11:03-Eval 02/05, test auc: 0.6394\n",
      "2022-12-22,19:11:04-Eval 03/05, test auc: 0.6966\n",
      "2022-12-22,19:11:06-Eval 04/05, test auc: 0.6218\n",
      "2022-12-22,19:11:08-Eval 05/05, test auc: 0.6290\n",
      "2022-12-22,19:11:08-Condensed data test AUC (TRSF-β): 0.6560±0.0322\n",
      "\n",
      "2022-12-22,19:11:08-Evaluating condensed data on network: TCN-β ...\n",
      "2022-12-22,19:11:09-Eval 01/05, test auc: 0.6611\n",
      "2022-12-22,19:11:10-Eval 02/05, test auc: 0.6418\n",
      "2022-12-22,19:11:11-Eval 03/05, test auc: 0.6716\n",
      "2022-12-22,19:11:12-Eval 04/05, test auc: 0.6716\n",
      "2022-12-22,19:11:13-Eval 05/05, test auc: 0.6318\n",
      "2022-12-22,19:11:13-Condensed data test AUC (TCN-β): 0.6556±0.0161\n",
      "\n",
      "2022-12-22,19:11:13-Evaluating condensed data on network: TCN-γ ...\n",
      "2022-12-22,19:11:15-Eval 01/05, test auc: 0.6422\n",
      "2022-12-22,19:11:16-Eval 02/05, test auc: 0.6476\n",
      "2022-12-22,19:11:18-Eval 03/05, test auc: 0.6817\n",
      "2022-12-22,19:11:19-Eval 04/05, test auc: 0.6393\n",
      "2022-12-22,19:11:21-Eval 05/05, test auc: 0.6397\n",
      "2022-12-22,19:11:21-Condensed data test AUC (TCN-γ): 0.6501±0.0161\n",
      "\n",
      "2022-12-22,19:11:21-Evaluating condensed data on network: LSTM-β ...\n",
      "2022-12-22,19:11:24-Eval 01/05, test auc: 0.6715\n",
      "2022-12-22,19:11:27-Eval 02/05, test auc: 0.6454\n",
      "2022-12-22,19:11:30-Eval 03/05, test auc: 0.6445\n",
      "2022-12-22,19:11:33-Eval 04/05, test auc: 0.6644\n",
      "2022-12-22,19:11:36-Eval 05/05, test auc: 0.6673\n",
      "2022-12-22,19:11:36-Condensed data test AUC (LSTM-β): 0.6586±0.0114\n",
      "\n",
      "2022-12-22,19:11:36-Evaluating condensed data on network: RNN-α ...\n",
      "2022-12-22,19:11:39-Eval 01/05, test auc: 0.6443\n",
      "2022-12-22,19:11:41-Eval 02/05, test auc: 0.6469\n",
      "2022-12-22,19:11:44-Eval 03/05, test auc: 0.6762\n",
      "2022-12-22,19:11:47-Eval 04/05, test auc: 0.6444\n",
      "2022-12-22,19:11:50-Eval 05/05, test auc: 0.6422\n",
      "2022-12-22,19:11:50-Condensed data test AUC (RNN-α): 0.6508±0.0128\n",
      "\n",
      "2022-12-22,19:11:50-Evaluating condensed data on network: RNN-β ...\n",
      "2022-12-22,19:11:53-Eval 01/05, test auc: 0.6460\n",
      "2022-12-22,19:11:55-Eval 02/05, test auc: 0.6506\n",
      "2022-12-22,19:11:58-Eval 03/05, test auc: 0.6487\n",
      "2022-12-22,19:12:01-Eval 04/05, test auc: 0.6336\n",
      "2022-12-22,19:12:04-Eval 05/05, test auc: 0.6469\n",
      "2022-12-22,19:12:04-Condensed data test AUC (RNN-β): 0.6452±0.0060\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#### Evaluate condensed data ####\n",
    "aucs = dict()\n",
    "for this_net in cf.dm.eval_net:  # iterates through all networks to evaluate condensed dataset\n",
    "    \n",
    "    logging.info(\"Evaluating condensed data on network: {} ...\".format(net_mp[this_net]))\n",
    "    aucs[this_net] = []\n",
    "\n",
    "    for it_eval in range(cf.dm.num_eval):\n",
    "        net_eval = get_net(this_net, **cf[this_net+\"_args\"]).to(cf.device)  # get a random model\n",
    "        # avoid any unaware modification\n",
    "        data_syn_eval, label_syn_eval = \\\n",
    "            copy.deepcopy(data_syn.detach()), copy.deepcopy(label_syn.detach())\n",
    "\n",
    "        # create a data loader from condensed dataset\n",
    "        syn_train_loader = create_data_loader(\n",
    "            data_syn_eval, label_syn_eval, batch_size=cf.train_batch, sampler=False)\n",
    "\n",
    "        # evaluate a network on this condensed dataset\n",
    "        _, test_auc = eval_net(\n",
    "            net_eval, syn_train_loader, val_loader, test_loader,\n",
    "            lr=cf.lr, epochs=cf.epochs, weight_decay=cf.weight_decay,\n",
    "            save_dir=cf.save_dir, val_metric=cf.val_metric, device=cf.device,\n",
    "            early_stop=cf.early_stop, early_stop_metric=cf.early_stop_metric,\n",
    "        )\n",
    "\n",
    "        logging.info(\"Eval {:02d}/{:02d}, test auc: {:.4f}\".format(it_eval+1, cf.dm.num_eval, test_auc), )\n",
    "        aucs[this_net].append(test_auc)\n",
    "\n",
    "    logging.info(\"Condensed data test AUC ({}): {:.4f}±{:.4f}\\n\".format(\n",
    "        net_mp[this_net], np.mean(aucs[this_net]), np.std(aucs[this_net])))\n",
    "    \n",
    "    if eval_metric.writer is not None:\n",
    "        eval_metric.writer.set_step(it, mode=\"eval\")\n",
    "    eval_metric.update(\"syn_auc ({})\".format(this_net), np.mean(aucs[this_net]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ac0ce744",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-12-22,19:12:04-Condensed data (80) test AUC (all 11 networks): 0.6515±0.0173\n"
     ]
    }
   ],
   "source": [
    "all_test_auc[\"iter_\" + str(it)] = aucs\n",
    "\n",
    "final_test_auc, auc_all = dict(), []\n",
    "    \n",
    "for this_net in cf.dm.eval_net:\n",
    "    final_test_auc[this_net]=aucs[this_net]\n",
    "    auc_all+=aucs[this_net]\n",
    "\n",
    "## overall test performance\n",
    "logging.info(\"Condensed data ({}) test AUC (all {} networks): {:.4f}±{:.4f}\".format(data_syn.shape[0],len(cf.dm.eval_net), np.mean(auc_all), np.std(auc_all)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2fc43d26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-12-22,19:12:04-Condensed dataset saved to : ../snapshots/Coswara_DC/syn_data.pt\n"
     ]
    }
   ],
   "source": [
    "# save condensed dataset\n",
    "syn_data_save_path = os.path.join(cf.save_dir, \"syn_data.pt\")\n",
    "data_save=[]\n",
    "data_save.append([copy.deepcopy(data_syn.detach().cpu()), copy.deepcopy(label_syn.detach().cpu())])\n",
    "torch.save(\n",
    "    {'syn_dataset': data_save,\n",
    "     'final_test_auc': final_test_auc,\n",
    "     \"all_test_auc\":all_test_auc},\n",
    "    syn_data_save_path)\n",
    "logging.info(\"Condensed dataset saved to : {}\".format(syn_data_save_path))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
