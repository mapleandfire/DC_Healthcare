{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e62f84e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### DEMO - Dataset condensation on MIMIC-III, 800 condensed samples\n",
    "\n",
    "### import modules\n",
    "import numpy as np\n",
    "from dataset.data_loaders import create_data_loader, build_data_getter\n",
    "import torch,os,copy,logging\n",
    "from configs.config_DM import get_args, get_config\n",
    "from utils.train_utils import get_net, eval_net\n",
    "from utils.misc import init_logging\n",
    "from utils.metric_tracker import MetricTracker, TensorboardWriter\n",
    "from dataset.meta import ds_name_mapping as ds_mp\n",
    "from dataset.meta import net_name_mapping as net_mp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a65b06fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-12-22,17:22:57-Dataset: MIMIC-III, results will be saved to: ../snapshots/MIMIC-III_DC\n"
     ]
    }
   ],
   "source": [
    "# get arugments and configs\n",
    "this_args = get_args(strict=False)\n",
    "\n",
    "## setting for MIMIC-III\n",
    "this_args.dataset=\"mimic3\"\n",
    "this_args.dm_ipc=400\n",
    "this_args.save_dir_name=\"MIMIC-III_DC\"\n",
    "this_args.pre_process=\"none\"\n",
    "\n",
    "cf=get_config(this_args)\n",
    "\n",
    "# create saving directory\n",
    "os.makedirs(cf.save_dir, exist_ok=True)\n",
    "log_root = logging.getLogger()\n",
    "init_logging(log_root, cf.save_dir)\n",
    "\n",
    "logging.info(f\"Dataset: {ds_mp[cf.ds_name]}, results will be saved to: {cf.save_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cf1288b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-12-22,17:22:57-Loading train set and creating validation/test data loader for: MIMIC-III\n",
      "2022-12-22,17:22:59-Number of samples - train: 14698, validation: 3222, test: 3236\n"
     ]
    }
   ],
   "source": [
    "# the real validation/test data loader\n",
    "logging.info(\"Loading train set and creating validation/test data loader for: {}\".format(ds_mp[cf.ds_name]))\n",
    "\n",
    "### the dataset are not included; please download and pre-process the datasets by yourselves\n",
    "_, val_loader, test_loader, tr_data, tr_lb, prpr = cf.data_loader_fn(\n",
    "    path=cf.data_root, train_batch=cf.train_batch, val_batch=128, test_batch=128, pre_process=cf.pre_process)\n",
    "\n",
    "logging.info(f\"Number of samples - train: {tr_data.shape[0]}, validation: {len(val_loader.dataset)}, test: {len(test_loader.dataset)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "61d833a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-12-22,17:22:59-Initialising condensed dataset from scratch, condensed samples: 800\n",
      "2022-12-22,17:23:01-Original train data shape: (14698, 48, 60), size: 322.954 MBs \n",
      "2022-12-22,17:23:01-Condensed data shape: (800, 48, 60), size: 8.789 MBs \n",
      "2022-12-22,17:23:01-Using Adam optimizer for DC learning ...\n",
      "2022-12-22,17:23:01-Learning condensed dataset on networks: ['TCN-α', 'LSTM-α', 'ViT-α']\n",
      "2022-12-22,17:23:01-Evaluating condensed dataset on networks: ['TCN-α', 'LSTM-α', 'ViT-α', 'ViT-β', 'TRSF-α', 'TRSF-β', 'TCN-β', 'TCN-γ', 'LSTM-β', 'RNN-α', 'RNN-β']\n"
     ]
    }
   ],
   "source": [
    "num_classes = 2 if cf.num_class==1 else cf.num_class  # find class number\n",
    "\n",
    "# build the original train data getter: get random n data from class c\n",
    "get_data = build_data_getter(cf.ds_name, tr_data, tr_lb, cf.device)\n",
    "\n",
    "syn_shape=(num_classes * cf.dm.ipc, cf.dm.syn_time_dim, cf.fea_dim,) # shape of condensed dataset\n",
    "\n",
    "logging.info(f\"Initialising condensed dataset from scratch, condensed samples: {num_classes * cf.dm.ipc}\")\n",
    "data_syn = torch.randn(size=syn_shape, dtype=torch.float, requires_grad=True, device=cf.device)\n",
    "\n",
    "logging.info(\"Original train data shape: {}, size: {:.3f} MBs \".format(tr_data.shape, tr_data.nbytes/(1024**2)))\n",
    "logging.info(\"Condensed data shape: {}, size: {:.3f} MBs \".format(syn_shape, data_syn.detach().cpu().numpy().nbytes/(1024**2)))\n",
    "\n",
    "if cf.ds_name == \"mimic3\" or cf.ds_name==\"physio\" or cf.ds_name == \"covid_b\":\n",
    "    label_syn = np.asarray([np.ones(cf.dm.ipc) * i for i in range(num_classes)])  # [0,0,0, ..., 1,1,1, ]\n",
    "    label_syn = torch.tensor(label_syn, dtype=cf.label_dtype, requires_grad=False, device=cf.device).view(-1)\n",
    "else:\n",
    "    raise NotImplementedError(\"Dataset {} not implemented\".format(cf.ds_name))\n",
    "\n",
    "logging.info(\"Using Adam optimizer for DC learning ...\")\n",
    "optimizer_data = torch.optim.Adam([data_syn, ], lr=cf.dm.lr_data)\n",
    "\n",
    "logging.info(\"Learning condensed dataset on networks: {}\".format([net_mp[e] for e in cf.dm.train_net]))\n",
    "logging.info(\"Evaluating condensed dataset on networks: {}\".format([net_mp[e] for e in cf.dm.eval_net]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9289d7fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-12-22,17:23:01-Creating tensborboard writer ...\n"
     ]
    }
   ],
   "source": [
    "# setup tensorboard writer \n",
    "logging.info(\"Creating tensborboard writer ...\")\n",
    "writer = TensorboardWriter(cf.save_dir, cf.enable_tensorboard)\n",
    "train_metrics = MetricTracker(\"mmd_loss\",writer=writer)\n",
    "eval_keys = tuple(\"syn_auc ({})\".format(n) for n in cf.dm.eval_net)\n",
    "eval_metric = MetricTracker(*eval_keys, writer=writer)\n",
    "all_test_auc = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a448a351",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-12-22,17:23:01-DC learning starts ...\n",
      "2022-12-22,17:23:03-iter = 0000, MMD loss = 0.0005218\n",
      "2022-12-22,17:25:08-iter = 1000, MMD loss = 0.0000057\n",
      "2022-12-22,17:27:14-iter = 2000, MMD loss = 0.0001203\n",
      "2022-12-22,17:29:17-iter = 3000, MMD loss = 0.0002191\n",
      "2022-12-22,17:31:22-iter = 4000, MMD loss = 0.0012017\n",
      "2022-12-22,17:33:22-iter = 5000, MMD loss = 0.0001374\n",
      "2022-12-22,17:35:25-iter = 6000, MMD loss = 0.0000077\n",
      "2022-12-22,17:37:23-iter = 7000, MMD loss = 0.0002133\n",
      "2022-12-22,17:39:29-iter = 8000, MMD loss = 0.0005034\n",
      "2022-12-22,17:41:26-iter = 9000, MMD loss = 0.0000416\n",
      "2022-12-22,17:43:31-iter = 10000, MMD loss = 0.0000174\n",
      "2022-12-22,17:45:35-iter = 11000, MMD loss = 0.0000008\n",
      "2022-12-22,17:47:34-iter = 12000, MMD loss = 0.0002754\n",
      "2022-12-22,17:49:38-iter = 13000, MMD loss = 0.0000254\n",
      "2022-12-22,17:51:41-iter = 14000, MMD loss = 0.0000019\n",
      "2022-12-22,17:53:40-iter = 15000, MMD loss = 0.0000896\n",
      "2022-12-22,17:55:43-iter = 16000, MMD loss = 0.0000019\n",
      "2022-12-22,17:57:50-iter = 17000, MMD loss = 0.0000003\n",
      "2022-12-22,17:59:54-iter = 18000, MMD loss = 0.0000196\n",
      "2022-12-22,18:01:57-iter = 19000, MMD loss = 0.0000003\n",
      "2022-12-22,18:04:03-iter = 20000, MMD loss = 0.0000129\n",
      "2022-12-22,18:06:03-iter = 21000, MMD loss = 0.0000207\n",
      "2022-12-22,18:08:01-iter = 22000, MMD loss = 0.0000118\n",
      "2022-12-22,18:10:04-iter = 23000, MMD loss = 0.0003996\n",
      "2022-12-22,18:12:06-iter = 24000, MMD loss = 0.0000532\n",
      "2022-12-22,18:12:06-Learning completed.\n"
     ]
    }
   ],
   "source": [
    "logging.info('DC learning starts ...')\n",
    "optimizer_data.zero_grad()\n",
    "\n",
    "#### Learn condensed data ######\n",
    "for it in range(cf.dm.iteration + 1):\n",
    "\n",
    "    tr_net = np.random.choice(cf.dm.train_net)   # randomly pick a network from train network candidates\n",
    "    net = get_net(tr_net, **cf[tr_net+\"_args\"]).to(cf.device)   # get a random model\n",
    "    net.train()\n",
    "    for param in list(net.parameters()):\n",
    "        param.requires_grad = False\n",
    "    loss_avg = 0\n",
    "\n",
    "    # compute MMD loss\n",
    "    loss = torch.tensor(0.0).to(cf.device)\n",
    "    for _, c in enumerate(range(num_classes)):\n",
    "        # the batch size should not exceed total samples of this class\n",
    "        this_batch_real = min(len(get_data.indices_class[c]), cf.dm.batch_real)\n",
    "        batch_data_real = get_data(c, this_batch_real)\n",
    "        batch_data_syn = data_syn[c * cf.dm.ipc : (c + 1) * cf.dm.ipc]\n",
    "\n",
    "        output_real = net(batch_data_real).detach()\n",
    "        output_syn = net(batch_data_syn)\n",
    "\n",
    "        loss += torch.sum((torch.mean(output_real, dim=0) - torch.mean(output_syn, dim=0)) ** 2)\n",
    "\n",
    "    # update condensed data\n",
    "    optimizer_data.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer_data.step()\n",
    "    loss_avg += loss.item()\n",
    "    loss_avg /= (num_classes)\n",
    "    if train_metrics.writer is not None:\n",
    "        train_metrics.writer.set_step(it)\n",
    "    train_metrics.update(\"mmd_loss\", loss_avg)\n",
    "\n",
    "    if it % cf.dm.logging_iter == 0:\n",
    "        logging.info('iter = {:04d}, MMD loss = {:.7f}'.format(it, loss_avg))\n",
    "        \n",
    "logging.info('Learning completed.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "52598d9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-12-22,18:12:06-Evaluating condensed data on network: TCN-α ...\n",
      "2022-12-22,18:12:18-Eval 01/05, test auc: 0.7427\n",
      "2022-12-22,18:12:30-Eval 02/05, test auc: 0.7468\n",
      "2022-12-22,18:12:42-Eval 03/05, test auc: 0.7523\n",
      "2022-12-22,18:12:54-Eval 04/05, test auc: 0.7469\n",
      "2022-12-22,18:13:05-Eval 05/05, test auc: 0.7524\n",
      "2022-12-22,18:13:05-Condensed data test AUC (TCN-α): 0.7482±0.0037\n",
      "\n",
      "2022-12-22,18:13:05-Evaluating condensed data on network: LSTM-α ...\n",
      "2022-12-22,18:13:15-Eval 01/05, test auc: 0.7637\n",
      "2022-12-22,18:13:26-Eval 02/05, test auc: 0.7775\n",
      "2022-12-22,18:13:36-Eval 03/05, test auc: 0.7734\n",
      "2022-12-22,18:13:47-Eval 04/05, test auc: 0.7665\n",
      "2022-12-22,18:13:57-Eval 05/05, test auc: 0.7735\n",
      "2022-12-22,18:13:57-Condensed data test AUC (LSTM-α): 0.7709±0.0050\n",
      "\n",
      "2022-12-22,18:13:57-Evaluating condensed data on network: ViT-α ...\n",
      "2022-12-22,18:14:12-Eval 01/05, test auc: 0.7386\n",
      "2022-12-22,18:14:26-Eval 02/05, test auc: 0.7368\n",
      "2022-12-22,18:14:40-Eval 03/05, test auc: 0.7494\n",
      "2022-12-22,18:14:54-Eval 04/05, test auc: 0.7498\n",
      "2022-12-22,18:15:08-Eval 05/05, test auc: 0.7426\n",
      "2022-12-22,18:15:08-Condensed data test AUC (ViT-α): 0.7435±0.0054\n",
      "\n",
      "2022-12-22,18:15:08-Evaluating condensed data on network: ViT-β ...\n",
      "2022-12-22,18:15:21-Eval 01/05, test auc: 0.7298\n",
      "2022-12-22,18:15:33-Eval 02/05, test auc: 0.7539\n",
      "2022-12-22,18:15:45-Eval 03/05, test auc: 0.7528\n",
      "2022-12-22,18:15:58-Eval 04/05, test auc: 0.7303\n",
      "2022-12-22,18:16:11-Eval 05/05, test auc: 0.7470\n",
      "2022-12-22,18:16:11-Condensed data test AUC (ViT-β): 0.7428±0.0106\n",
      "\n",
      "2022-12-22,18:16:11-Evaluating condensed data on network: TRSF-α ...\n",
      "2022-12-22,18:16:19-Eval 01/05, test auc: 0.7451\n",
      "2022-12-22,18:16:26-Eval 02/05, test auc: 0.7456\n",
      "2022-12-22,18:16:34-Eval 03/05, test auc: 0.7457\n",
      "2022-12-22,18:16:41-Eval 04/05, test auc: 0.7477\n",
      "2022-12-22,18:16:49-Eval 05/05, test auc: 0.7364\n",
      "2022-12-22,18:16:49-Condensed data test AUC (TRSF-α): 0.7441±0.0039\n",
      "\n",
      "2022-12-22,18:16:49-Evaluating condensed data on network: TRSF-β ...\n",
      "2022-12-22,18:16:57-Eval 01/05, test auc: 0.7329\n",
      "2022-12-22,18:17:04-Eval 02/05, test auc: 0.7401\n",
      "2022-12-22,18:17:12-Eval 03/05, test auc: 0.7385\n",
      "2022-12-22,18:17:19-Eval 04/05, test auc: 0.7323\n",
      "2022-12-22,18:17:27-Eval 05/05, test auc: 0.7421\n",
      "2022-12-22,18:17:27-Condensed data test AUC (TRSF-β): 0.7372±0.0039\n",
      "\n",
      "2022-12-22,18:17:27-Evaluating condensed data on network: TCN-β ...\n",
      "2022-12-22,18:17:33-Eval 01/05, test auc: 0.7475\n",
      "2022-12-22,18:17:38-Eval 02/05, test auc: 0.7498\n",
      "2022-12-22,18:17:44-Eval 03/05, test auc: 0.7456\n",
      "2022-12-22,18:17:50-Eval 04/05, test auc: 0.7279\n",
      "2022-12-22,18:17:56-Eval 05/05, test auc: 0.7168\n",
      "2022-12-22,18:17:56-Condensed data test AUC (TCN-β): 0.7375±0.0130\n",
      "\n",
      "2022-12-22,18:17:56-Evaluating condensed data on network: TCN-γ ...\n",
      "2022-12-22,18:18:06-Eval 01/05, test auc: 0.7447\n",
      "2022-12-22,18:18:16-Eval 02/05, test auc: 0.7471\n",
      "2022-12-22,18:18:24-Eval 03/05, test auc: 0.7449\n",
      "2022-12-22,18:18:34-Eval 04/05, test auc: 0.7482\n",
      "2022-12-22,18:18:42-Eval 05/05, test auc: 0.7578\n",
      "2022-12-22,18:18:42-Condensed data test AUC (TCN-γ): 0.7485±0.0048\n",
      "\n",
      "2022-12-22,18:18:42-Evaluating condensed data on network: LSTM-β ...\n",
      "2022-12-22,18:18:53-Eval 01/05, test auc: 0.7756\n",
      "2022-12-22,18:19:04-Eval 02/05, test auc: 0.7723\n",
      "2022-12-22,18:19:14-Eval 03/05, test auc: 0.7824\n",
      "2022-12-22,18:19:25-Eval 04/05, test auc: 0.7718\n",
      "2022-12-22,18:19:36-Eval 05/05, test auc: 0.7794\n",
      "2022-12-22,18:19:36-Condensed data test AUC (LSTM-β): 0.7763±0.0041\n",
      "\n",
      "2022-12-22,18:19:36-Evaluating condensed data on network: RNN-α ...\n",
      "2022-12-22,18:19:47-Eval 01/05, test auc: 0.7574\n",
      "2022-12-22,18:19:58-Eval 02/05, test auc: 0.7635\n",
      "2022-12-22,18:20:08-Eval 03/05, test auc: 0.7668\n",
      "2022-12-22,18:20:18-Eval 04/05, test auc: 0.7555\n",
      "2022-12-22,18:20:29-Eval 05/05, test auc: 0.7454\n",
      "2022-12-22,18:20:29-Condensed data test AUC (RNN-α): 0.7577±0.0074\n",
      "\n",
      "2022-12-22,18:20:29-Evaluating condensed data on network: RNN-β ...\n",
      "2022-12-22,18:20:40-Eval 01/05, test auc: 0.7848\n",
      "2022-12-22,18:20:50-Eval 02/05, test auc: 0.7729\n",
      "2022-12-22,18:21:01-Eval 03/05, test auc: 0.7243\n",
      "2022-12-22,18:21:12-Eval 04/05, test auc: 0.7511\n",
      "2022-12-22,18:21:23-Eval 05/05, test auc: 0.7522\n",
      "2022-12-22,18:21:23-Condensed data test AUC (RNN-β): 0.7571±0.0207\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#### Evaluate condensed data ####\n",
    "aucs = dict()\n",
    "for this_net in cf.dm.eval_net:  # iterates through all networks to evaluate condensed dataset\n",
    "    \n",
    "    logging.info(\"Evaluating condensed data on network: {} ...\".format(net_mp[this_net]))\n",
    "    aucs[this_net] = []\n",
    "\n",
    "    for it_eval in range(cf.dm.num_eval):\n",
    "        net_eval = get_net(this_net, **cf[this_net+\"_args\"]).to(cf.device)  # get a random model\n",
    "        # avoid any unaware modification\n",
    "        data_syn_eval, label_syn_eval = \\\n",
    "            copy.deepcopy(data_syn.detach()), copy.deepcopy(label_syn.detach())\n",
    "\n",
    "        # create a data loader from condensed dataset\n",
    "        syn_train_loader = create_data_loader(\n",
    "            data_syn_eval, label_syn_eval, batch_size=cf.train_batch, sampler=False)\n",
    "\n",
    "        # evaluate a network on this condensed dataset\n",
    "        _, test_auc = eval_net(\n",
    "            net_eval, syn_train_loader, val_loader, test_loader,\n",
    "            lr=cf.lr, epochs=cf.epochs, weight_decay=cf.weight_decay,\n",
    "            save_dir=cf.save_dir, val_metric=cf.val_metric, device=cf.device,\n",
    "            early_stop=cf.early_stop, early_stop_metric=cf.early_stop_metric,\n",
    "        )\n",
    "\n",
    "        logging.info(\"Eval {:02d}/{:02d}, test auc: {:.4f}\".format(it_eval+1, cf.dm.num_eval, test_auc), )\n",
    "        aucs[this_net].append(test_auc)\n",
    "\n",
    "    logging.info(\"Condensed data test AUC ({}): {:.4f}±{:.4f}\\n\".format(\n",
    "        net_mp[this_net], np.mean(aucs[this_net]), np.std(aucs[this_net])))\n",
    "    \n",
    "    if eval_metric.writer is not None:\n",
    "        eval_metric.writer.set_step(it, mode=\"eval\")\n",
    "    eval_metric.update(\"syn_auc ({})\".format(this_net), np.mean(aucs[this_net]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ac0ce744",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-12-22,18:21:23-Condensed data (800) test AUC (all 11 networks): 0.7513±0.0153\n"
     ]
    }
   ],
   "source": [
    "all_test_auc[\"iter_\" + str(it)] = aucs\n",
    "\n",
    "final_test_auc, auc_all = dict(), []\n",
    "    \n",
    "for this_net in cf.dm.eval_net:\n",
    "    final_test_auc[this_net]=aucs[this_net]\n",
    "    auc_all+=aucs[this_net]\n",
    "\n",
    "## overall test performance\n",
    "logging.info(\"Condensed data ({}) test AUC (all {} networks): {:.4f}±{:.4f}\".format(data_syn.shape[0],len(cf.dm.eval_net), np.mean(auc_all), np.std(auc_all)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2fc43d26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-12-22,18:21:23-Condensed dataset saved to : ../snapshots/MIMIC-III_DC/syn_data.pt\n"
     ]
    }
   ],
   "source": [
    "# save condensed dataset\n",
    "syn_data_save_path = os.path.join(cf.save_dir, \"syn_data.pt\")\n",
    "data_save=[]\n",
    "data_save.append([copy.deepcopy(data_syn.detach().cpu()), copy.deepcopy(label_syn.detach().cpu())])\n",
    "torch.save(\n",
    "    {'syn_dataset': data_save,\n",
    "     'final_test_auc': final_test_auc,\n",
    "     \"all_test_auc\":all_test_auc},\n",
    "    syn_data_save_path)\n",
    "logging.info(\"Condensed dataset saved to : {}\".format(syn_data_save_path))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
